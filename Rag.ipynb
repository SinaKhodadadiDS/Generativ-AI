{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1.  Installations and Settings 🛠️"
      ],
      "metadata": {
        "id": "zIlMll94nfgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yT7y6hC7nWfQ"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "uv pip install -q llama-index-core\n",
        "uv pip install -q llama-index-llms-groq\n",
        "uv pip install -q llama-index-readers-file\n",
        "uv pip install -q llama-index-embeddings-huggingface\n",
        "uv pip install -q llama-index-embeddings-instructor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "KgE5welOtaPa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Set the token as an environ variable\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ[\"sina_hug_tocken\"] = userdata.get(\"sina_hug_tocken\")"
      ],
      "metadata": {
        "id": "Ovk1-O3ftKgs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "\n",
        "# This info's at the top of each HuggingFace model page\n",
        "model = \"llama3-70b-8192\"\n",
        "\n",
        "llm = Groq(\n",
        "    model=model)"
      ],
      "metadata": {
        "id": "1AixHi8sGOk0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our model need some information to work."
      ],
      "metadata": {
        "id": "wsu_JienyMZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p /content/data\n",
        "!wget -O /content/data/The_Republic_of_Plato.txt https://www.gutenberg.org/cache/epub/55201/pg55201.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4jNfOjgyMAK",
        "outputId": "e2d05901-fd1d-4c18-d70c-6ee2f79dbebc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-06 15:20:40--  https://www.gutenberg.org/cache/epub/55201/pg55201.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1457578 (1.4M) [text/plain]\n",
            "Saving to: ‘/content/data/The_Republic_of_Plato.txt’\n",
            "\n",
            "/content/data/The_R 100%[===================>]   1.39M  2.39MB/s    in 0.6s    \n",
            "\n",
            "2025-05-06 15:20:43 (2.39 MB/s) - ‘/content/data/The_Republic_of_Plato.txt’ saved [1457578/1457578]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()"
      ],
      "metadata": {
        "id": "ED2Q7hpV5inf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large documents, like books, are too big for models to handle all at once. To make them easier to process, we split them into smaller parts, called chunks. These chunks can be split:\n",
        "\n",
        "By `sentences` – keeping full sentences together.\n",
        "\n",
        "\n",
        "By `tokens` – based on model input limits (tokens = pieces of words).\n",
        "\n",
        "\n",
        "By `meaning` (semantics) – keeping related ideas grouped."
      ],
      "metadata": {
        "id": "6b8g4pfS9Dtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "text_splitter = SentenceSplitter(chunk_size=800, chunk_overlap=150)\n",
        "\n",
        "docs = text_splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "1oAFOdvr9C-Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating vectors with embeddings**\n",
        "\n",
        "Embeddings are a fancy way of saying we turn words into numbers that computers can understand. Each word gets its own unique code, based on its meaning and relationship to other words. The list of numbers produced is known as a vector. Vectors allow us to compare text and find chunks that contain similar information"
      ],
      "metadata": {
        "id": "3vXgtWhk-o5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings_folder = \"/content/embedding_model/\"\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbedding(\n",
        "                                   model_name = embedding_model,\n",
        "                                   cache_folder = embeddings_folder)"
      ],
      "metadata": {
        "id": "7sls9Zha-xU_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Sina is my friend\"\n",
        "query_result = embeddings.get_text_embedding(test_text)\n",
        "query_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnaCHyXL_Zvo",
        "outputId": "09985651-f7ec-4722-b007-67bf60d05702"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.08157619088888168,\n",
              " 0.04829923063516617,\n",
              " -0.09897464513778687,\n",
              " -0.017182614654302597,\n",
              " -0.03681368753314018,\n",
              " 0.03711341693997383,\n",
              " 0.07499756664037704,\n",
              " -0.028513623401522636,\n",
              " 0.04212306812405586,\n",
              " 0.006139792501926422,\n",
              " 0.01407662034034729,\n",
              " -0.06968077272176743,\n",
              " -0.06041228026151657,\n",
              " 0.06358020007610321,\n",
              " 0.06774589419364929,\n",
              " -0.033906325697898865,\n",
              " 0.07246381789445877,\n",
              " -0.003503041807562113,\n",
              " -0.034613173454999924,\n",
              " -0.06648339331150055,\n",
              " -0.04274279996752739,\n",
              " 0.03157821670174599,\n",
              " 0.008334643207490444,\n",
              " -0.027281727641820908,\n",
              " -0.08411352336406708,\n",
              " 0.05708814784884453,\n",
              " 0.056152693927288055,\n",
              " -0.0463726781308651,\n",
              " -0.03786627948284149,\n",
              " -0.102239228785038,\n",
              " -0.025849023833870888,\n",
              " 0.12577001750469208,\n",
              " -0.06357301026582718,\n",
              " -0.05562366172671318,\n",
              " -0.03052680753171444,\n",
              " 0.06544873863458633,\n",
              " -0.030589813366532326,\n",
              " -0.04039536789059639,\n",
              " -0.0035911700688302517,\n",
              " 0.05368359386920929,\n",
              " -0.029433434829115868,\n",
              " 0.07776978611946106,\n",
              " 0.01670188643038273,\n",
              " -0.06749193370342255,\n",
              " -0.09282580018043518,\n",
              " -0.0965992659330368,\n",
              " 0.0020811145659536123,\n",
              " 0.0422838069498539,\n",
              " 0.08372344076633453,\n",
              " -0.05558027699589729,\n",
              " -0.014252269640564919,\n",
              " 0.030366716906428337,\n",
              " -0.09510447084903717,\n",
              " 0.04399145767092705,\n",
              " -0.01652332954108715,\n",
              " 0.032905805855989456,\n",
              " 0.008918692357838154,\n",
              " -0.06810439378023148,\n",
              " 0.027781382203102112,\n",
              " 0.015581940300762653,\n",
              " 0.02614676207304001,\n",
              " 0.03368210047483444,\n",
              " -0.010163741186261177,\n",
              " 0.015726648271083832,\n",
              " -0.027912292629480362,\n",
              " 0.0011412804014980793,\n",
              " 0.02008790522813797,\n",
              " 0.05302964895963669,\n",
              " -0.07559600472450256,\n",
              " -0.012295527383685112,\n",
              " -0.06442143768072128,\n",
              " 0.010165182873606682,\n",
              " -0.02260943502187729,\n",
              " 0.11888795346021652,\n",
              " -0.03862231969833374,\n",
              " -0.03931662067770958,\n",
              " 0.0009303978295065463,\n",
              " -0.0031844675540924072,\n",
              " 0.033197011798620224,\n",
              " 0.02318078652024269,\n",
              " -0.07633589208126068,\n",
              " -0.015370282344520092,\n",
              " -0.04665469005703926,\n",
              " 0.008779099211096764,\n",
              " 0.06065094843506813,\n",
              " 0.030749233439564705,\n",
              " -0.07418742030858994,\n",
              " 0.004771035630255938,\n",
              " 0.0631537213921547,\n",
              " 0.02554338611662388,\n",
              " 0.057288721203804016,\n",
              " 0.1410679817199707,\n",
              " -0.01914498396217823,\n",
              " -0.03212732821702957,\n",
              " 0.0576433502137661,\n",
              " -0.041316352784633636,\n",
              " 0.03637271001935005,\n",
              " -0.021590763702988625,\n",
              " -0.1695089489221573,\n",
              " 0.10896700620651245,\n",
              " -0.03947779908776283,\n",
              " 0.00803397037088871,\n",
              " 0.03819546103477478,\n",
              " -0.005273055285215378,\n",
              " -0.0343867689371109,\n",
              " 0.042943719774484634,\n",
              " 0.03085416741669178,\n",
              " 0.036953143775463104,\n",
              " 0.036787062883377075,\n",
              " -0.027883583679795265,\n",
              " -0.006734859198331833,\n",
              " 0.027568496763706207,\n",
              " -0.03107868880033493,\n",
              " -0.06371405720710754,\n",
              " 0.09966320544481277,\n",
              " 0.0675131157040596,\n",
              " -0.006103916559368372,\n",
              " 0.024084320291876793,\n",
              " 0.004780360963195562,\n",
              " 0.008179133757948875,\n",
              " 0.016017576679587364,\n",
              " 0.008773823268711567,\n",
              " 0.012786352075636387,\n",
              " 0.08232353627681732,\n",
              " 0.04745633900165558,\n",
              " -0.0850401446223259,\n",
              " -0.07558499276638031,\n",
              " -3.5306042621924485e-33,\n",
              " 0.0638020858168602,\n",
              " 0.07022152841091156,\n",
              " -0.005052908323705196,\n",
              " 0.015327404253184795,\n",
              " -0.0007484685047529638,\n",
              " -0.007939214818179607,\n",
              " -0.03991040959954262,\n",
              " 0.00012101689935661852,\n",
              " -0.0720132440328598,\n",
              " -0.045228686183691025,\n",
              " -0.06890977174043655,\n",
              " 0.040592070668935776,\n",
              " -0.0819413810968399,\n",
              " -0.0277094729244709,\n",
              " 0.01756838895380497,\n",
              " 0.03259141743183136,\n",
              " 0.04252883791923523,\n",
              " 0.014907902106642723,\n",
              " -0.0374179370701313,\n",
              " -0.055566251277923584,\n",
              " 0.03719893842935562,\n",
              " -0.006971689406782389,\n",
              " 0.0844641625881195,\n",
              " -0.042599696666002274,\n",
              " -0.005064045079052448,\n",
              " 0.03205685317516327,\n",
              " 0.08457709103822708,\n",
              " -0.05311620607972145,\n",
              " 0.07428871840238571,\n",
              " 0.02546600066125393,\n",
              " 0.02971755340695381,\n",
              " -0.006037975661456585,\n",
              " 0.07322897762060165,\n",
              " -0.029010655358433723,\n",
              " 0.0648563802242279,\n",
              " -0.00850760843604803,\n",
              " -0.07791826128959656,\n",
              " -0.09160537272691727,\n",
              " -0.08407115936279297,\n",
              " 0.029316851869225502,\n",
              " 0.09618768841028214,\n",
              " 0.04708554223179817,\n",
              " 0.013042264617979527,\n",
              " -0.009299034252762794,\n",
              " -0.03787568211555481,\n",
              " -0.03172631934285164,\n",
              " -0.023994693532586098,\n",
              " -0.014745953492820263,\n",
              " 0.0028839344158768654,\n",
              " 0.01026251632720232,\n",
              " -0.01707114279270172,\n",
              " -0.04400491341948509,\n",
              " 0.0008912528865039349,\n",
              " 0.03380407765507698,\n",
              " -0.09172721207141876,\n",
              " -0.040252845734357834,\n",
              " 0.04584348574280739,\n",
              " -0.04978421330451965,\n",
              " -0.037955351173877716,\n",
              " 0.017962515354156494,\n",
              " -0.04075909033417702,\n",
              " -0.025967037305235863,\n",
              " -0.00018367762095294893,\n",
              " -0.10482730716466904,\n",
              " -0.04864060878753662,\n",
              " 0.001743884407915175,\n",
              " -0.04963502287864685,\n",
              " -0.04024689644575119,\n",
              " 0.07634210586547852,\n",
              " -0.04895077645778656,\n",
              " 0.007957177236676216,\n",
              " 0.011383725330233574,\n",
              " -0.005333850625902414,\n",
              " 0.04823156073689461,\n",
              " 0.039221614599227905,\n",
              " -0.07391612976789474,\n",
              " -0.03668715059757233,\n",
              " 0.0620468445122242,\n",
              " -0.05586874485015869,\n",
              " 0.05027328431606293,\n",
              " 0.009506658650934696,\n",
              " -0.027505850419402122,\n",
              " 0.014537423849105835,\n",
              " -0.021442197263240814,\n",
              " -0.041930437088012695,\n",
              " 0.03987479582428932,\n",
              " 0.08418386429548264,\n",
              " -0.09815661609172821,\n",
              " -0.020293358713388443,\n",
              " 0.007742753252387047,\n",
              " -0.043535444885492325,\n",
              " 0.07600007206201553,\n",
              " 0.12782390415668488,\n",
              " -0.016677971929311752,\n",
              " 0.007175299804657698,\n",
              " 2.2625318333902363e-33,\n",
              " -0.0859161764383316,\n",
              " -0.015212194062769413,\n",
              " 0.017665555700659752,\n",
              " -0.03094853088259697,\n",
              " 0.07740263640880585,\n",
              " 0.0009310563909821212,\n",
              " 0.019100839272141457,\n",
              " 0.07938680052757263,\n",
              " -0.0014758063480257988,\n",
              " 0.00020215768017806113,\n",
              " -0.02375013567507267,\n",
              " -0.0020793923176825047,\n",
              " 0.06407634913921356,\n",
              " -0.041300319135189056,\n",
              " 0.07683520019054413,\n",
              " 0.05279707908630371,\n",
              " 0.07644762843847275,\n",
              " -0.016966773197054863,\n",
              " 0.02258533053100109,\n",
              " -0.039961572736501694,\n",
              " -0.08937011659145355,\n",
              " -0.0003198090707883239,\n",
              " -0.0031898007728159428,\n",
              " 0.0016821972094476223,\n",
              " 0.03429865464568138,\n",
              " -0.06014564633369446,\n",
              " 0.006611873395740986,\n",
              " -0.014091064222157001,\n",
              " -0.032055921852588654,\n",
              " -0.01617645099759102,\n",
              " 0.04666828736662865,\n",
              " 0.054082587361335754,\n",
              " -0.14868243038654327,\n",
              " -0.06119336187839508,\n",
              " -0.02555081807076931,\n",
              " 0.0245349258184433,\n",
              " -0.033357568085193634,\n",
              " 0.06657740473747253,\n",
              " -0.03873686492443085,\n",
              " -0.027114972472190857,\n",
              " 0.03484039008617401,\n",
              " -0.026944955810904503,\n",
              " 0.018132755532860756,\n",
              " 0.12147027254104614,\n",
              " -0.050841301679611206,\n",
              " -0.05931629240512848,\n",
              " 0.07951869815587997,\n",
              " 0.03951667621731758,\n",
              " -0.06908874213695526,\n",
              " 0.09550674259662628,\n",
              " -0.008528169244527817,\n",
              " -0.09061417728662491,\n",
              " 0.06981825083494186,\n",
              " 0.015579181723296642,\n",
              " 0.02218456380069256,\n",
              " -0.04695682227611542,\n",
              " 0.0006328163435682654,\n",
              " 0.0013108422281220555,\n",
              " -0.06299823522567749,\n",
              " -0.007692100014537573,\n",
              " 0.04280269145965576,\n",
              " -0.05368060991168022,\n",
              " 0.022155895829200745,\n",
              " 0.06170934438705444,\n",
              " 0.07413017004728317,\n",
              " 0.04854797571897507,\n",
              " 2.9737162549281493e-05,\n",
              " 0.005754272919148207,\n",
              " -0.03980187699198723,\n",
              " 0.08219649642705917,\n",
              " -0.07402483373880386,\n",
              " 0.030470550060272217,\n",
              " -0.13026908040046692,\n",
              " -0.025476012378931046,\n",
              " -0.031074706465005875,\n",
              " -0.08190032839775085,\n",
              " -0.03499741852283478,\n",
              " -0.024087531492114067,\n",
              " -0.04905685782432556,\n",
              " -0.013903745450079441,\n",
              " 0.006507342681288719,\n",
              " 0.05240362882614136,\n",
              " -0.07210534065961838,\n",
              " -0.033217161893844604,\n",
              " 0.05705063045024872,\n",
              " 0.033987801522016525,\n",
              " 0.07919761538505554,\n",
              " 0.023662349209189415,\n",
              " 0.006087717600166798,\n",
              " 0.10305052250623703,\n",
              " -0.007102243602275848,\n",
              " 0.02480071224272251,\n",
              " -0.019077889621257782,\n",
              " -0.05763840675354004,\n",
              " 0.012263751588761806,\n",
              " -1.4461726927095242e-08,\n",
              " -0.0387597419321537,\n",
              " -0.03141665458679199,\n",
              " -0.03432951122522354,\n",
              " -0.027245689183473587,\n",
              " 0.037326324731111526,\n",
              " 0.029578451067209244,\n",
              " 0.058148983865976334,\n",
              " -0.04167306423187256,\n",
              " 0.014720668084919453,\n",
              " 0.03785918280482292,\n",
              " 0.044569842517375946,\n",
              " 0.07445980608463287,\n",
              " 0.07720953226089478,\n",
              " 0.0074759842827916145,\n",
              " 0.011749809607863426,\n",
              " 0.049880869686603546,\n",
              " -0.003442661836743355,\n",
              " 0.06730271130800247,\n",
              " 0.046767689287662506,\n",
              " -0.01585547998547554,\n",
              " 0.13105279207229614,\n",
              " 0.05808427184820175,\n",
              " 0.1311078518629074,\n",
              " 0.025182368233799934,\n",
              " -0.013790804892778397,\n",
              " -0.0405014269053936,\n",
              " 0.032287854701280594,\n",
              " 0.006903968285769224,\n",
              " 0.019856786355376244,\n",
              " 0.029600588604807854,\n",
              " 0.028158631175756454,\n",
              " 0.01915047876536846,\n",
              " 0.04368394985795021,\n",
              " -0.010844841599464417,\n",
              " 0.038153789937496185,\n",
              " -0.0032989615574479103,\n",
              " -0.019194526597857475,\n",
              " -0.047777097672224045,\n",
              " -0.017723575234413147,\n",
              " 0.0026085427962243557,\n",
              " 0.04239020124077797,\n",
              " 0.07965318858623505,\n",
              " 0.00808367133140564,\n",
              " 0.02519828826189041,\n",
              " -0.05681828781962395,\n",
              " -0.058583956211805344,\n",
              " 0.06843069940805435,\n",
              " -0.10090906172990799,\n",
              " 0.0190317053347826,\n",
              " -0.050142984837293625,\n",
              " -0.002969624474644661,\n",
              " 0.021022316068410873,\n",
              " 0.015526851639151573,\n",
              " -0.011064757592976093,\n",
              " 0.02590750716626644,\n",
              " -0.044716715812683105,\n",
              " 0.005329037085175514,\n",
              " 0.07616288214921951,\n",
              " 0.008663199841976166,\n",
              " 0.03620583936572075,\n",
              " 0.035848479717969894,\n",
              " -0.05573493614792824,\n",
              " -0.045688629150390625,\n",
              " -0.018880218267440796]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "characters = len(test_text)\n",
        "dimensions = len(query_result)\n",
        "print(\n",
        "    f\"The {characters} character sentence was transformed into a {dimensions} dimension vector\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow1JqffR_rtn",
        "outputId": "50b2a554-976d-475e-f219-c1aa6cf2d69e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 17 character sentence was transformed into a 384 dimension vector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a vector database**\n",
        "\n",
        "Imagine a library where books aren't just filed alphabetically, but also by their themes, characters, and emotions. That's the magic of vector databases: they unlock information beyond keywords, connecting ideas in unexpected ways."
      ],
      "metadata": {
        "id": "IGH9D8FaAclg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "                                                documents,\n",
        "                                                transformations = [text_splitter],\n",
        "                                                embed_model = embeddings)"
      ],
      "metadata": {
        "id": "0Y1TGj_TAfix"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I want to save the database"
      ],
      "metadata": {
        "id": "6vya6vAqERnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index.storage_context.persist(persist_dir=\"/content/vector_index\")"
      ],
      "metadata": {
        "id": "PdariUr5EVFX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code below is for future, when we want to load the database:\n",
        "\n",
        "# from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "# storage_context = StorageContext.from_defaults(persist_dir=\"/content/vector_index\")\n",
        "# vector_index = load_index_from_storage(storage_context, embed_model=embeddings)"
      ],
      "metadata": {
        "id": "hCLF-cCLEibw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a prompt**\n",
        "\n",
        "We can guide our model's behavior with a prompt."
      ],
      "metadata": {
        "id": "Jwwu22xzFEZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "input_template = \"\"\"Here is the context:\n",
        "{context_str}\n",
        "\n",
        "Answer the question based only on the following context. Keep your answers short and succinct.\n",
        "Question to be answered: {query_str}\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=input_template)"
      ],
      "metadata": {
        "id": "eKsGJUz-EqMx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RAG - chaining it all together**\n",
        "\n",
        "This is the final piece of the puzzle:\n",
        "\n",
        "we now drive everything with an engine. Our vector database, our prompt, and our LLM join to give us retrieval augmented generation"
      ],
      "metadata": {
        "id": "kvYdTBtzFh4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(\n",
        "                                            llm=llm,\n",
        "                                            text_qa_template=prompt,\n",
        "                                            similarity_top_k=2,\n",
        "                                            response_mode=\"tree_summarize\")"
      ],
      "metadata": {
        "id": "ZjRMkFirFbiT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our model"
      ],
      "metadata": {
        "id": "XW_hzgtZGh5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = await query_engine.aquery(\"Who is Plato?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWO2i8b6Gsr3",
        "outputId": "7e96fa32-39ac-479c-ea8e-ee454a3c2f2f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plato is a philosopher who has deeply meditated on the 'way of life of Pythagoras' and his followers, and has been influenced by Pythagoreanism in his philosophy and the form of his State.\n"
          ]
        }
      ]
    }
  ]
}